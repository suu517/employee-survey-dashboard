#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾“æ¥­å“¡èª¿æŸ»å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ç‰ˆï¼‰
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from datetime import datetime
import os
import re

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Employee Survey Dashboard",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªCSS
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Inter', 'Helvetica Neue', 'Arial', sans-serif;
        background-color: #f8fafc;
    }
    
    .main > div {
        padding-top: 2rem;
    }
    
    h1, h2, h3, h4, h5, h6 {
        color: #1e293b;
        font-weight: 600;
        letter-spacing: -0.025em;
    }
    
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 12px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
    }
    
    .main-header h1 {
        color: white;
        margin: 0;
        font-size: 2.5rem;
        font-weight: 700;
    }
    
    .main-header p {
        color: rgba(255, 255, 255, 0.9);
        margin: 0.5rem 0 0 0;
        font-size: 1.1rem;
    }
    
    .kpi-container {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 1.5rem;
        margin-bottom: 2rem;
    }
    
    .kpi-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        border-left: 4px solid #3b82f6;
        transition: transform 0.2s ease, box-shadow 0.2s ease;
        position: relative;
        overflow: hidden;
    }
    
    .kpi-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
    }
    
    .kpi-card::before {
        content: '';
        position: absolute;
        top: 0;
        right: 0;
        width: 60px;
        height: 60px;
        background: linear-gradient(135deg, rgba(59, 130, 246, 0.1), rgba(59, 130, 246, 0.05));
        border-radius: 50%;
        transform: translate(20px, -20px);
    }
    
    .kpi-title {
        font-size: 0.875rem;
        font-weight: 500;
        color: #64748b;
        margin-bottom: 0.5rem;
        text-transform: uppercase;
        letter-spacing: 0.05em;
    }
    
    .kpi-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1e293b;
        margin-bottom: 0.5rem;
        line-height: 1;
    }
    
    .kpi-description {
        font-size: 0.875rem;
        color: #64748b;
        font-weight: 400;
    }
    
    .kpi-positive {
        border-left-color: #10b981;
    }
    
    .kpi-positive::before {
        background: linear-gradient(135deg, rgba(16, 185, 129, 0.1), rgba(16, 185, 129, 0.05));
    }
    
    .kpi-warning {
        border-left-color: #f59e0b;
    }
    
    .kpi-warning::before {
        background: linear-gradient(135deg, rgba(245, 158, 11, 0.1), rgba(245, 158, 11, 0.05));
    }
    
    .kpi-negative {
        border-left-color: #ef4444;
    }
    
    .kpi-negative::before {
        background: linear-gradient(135deg, rgba(239, 68, 68, 0.1), rgba(239, 68, 68, 0.05));
    }
    
    .section-header {
        background: white;
        padding: 1.5rem 2rem;
        border-radius: 12px;
        margin-bottom: 1.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #3b82f6;
    }
    
    .section-header h2 {
        margin: 0;
        color: #1e293b;
        font-size: 1.5rem;
        font-weight: 600;
    }
    
    .chart-container {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        margin-bottom: 1.5rem;
    }
    
    .sidebar .sidebar-content {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    
    .stSelectbox > div > div {
        background-color: white;
        border: 1px solid #d1d5db;
        border-radius: 8px;
    }
    
    .stRadio > div {
        background-color: white;
        border-radius: 8px;
        padding: 1rem;
        border: 1px solid #e5e7eb;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 0;
        background-color: #f1f5f9;
        border-radius: 8px;
        padding: 4px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 40px;
        border-radius: 6px;
        color: #64748b;
        font-weight: 500;
        background-color: transparent;
        border: none;
    }
    
    .stTabs [aria-selected="true"] {
        background-color: white !important;
        color: #1e293b !important;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    .dataframe {
        border: none !important;
    }
    
    .dataframe thead th {
        background-color: #f8fafc !important;
        color: #374151 !important;
        font-weight: 600 !important;
        border: none !important;
        padding: 12px !important;
    }
    
    .dataframe tbody td {
        border: none !important;
        padding: 12px !important;
        background-color: white !important;
    }
    
    .dataframe tbody tr:nth-child(even) td {
        background-color: #f9fafb !important;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    }
</style>
""", unsafe_allow_html=True)

# å®Ÿéš›ã®ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆé …ç›®å®šç¾©
SURVEY_CATEGORIES = {
    "Work Environment": {
        "work_hours": "è‡ªåˆ†ã«åˆã£ãŸå‹¤å‹™æ™‚é–“ã§åƒã‘ã‚‹",
        "holidays": "ä¼‘æ—¥ä¼‘æš‡ãŒã¡ã‚ƒã‚“ã¨å–ã‚Œã‚‹", 
        "paid_leave": "æœ‰çµ¦ä¼‘æš‡ãŒã¡ã‚ƒã‚“ã¨å–ã‚Œã‚‹",
        "flex_work": "æŸ”è»Ÿãªå‹¤å‹™ä½“ç³»ï¼ˆãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã€æ™‚çŸ­å‹¤å‹™ã€ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹åˆ¶ãªã©ï¼‰",
        "commute": "è‡ªå®…ã‹ã‚‰é©åˆ‡ãªè·é›¢ã§åƒã‘ã‚‹",
        "job_transfer": "è‡ªèº«ã®å¸Œæœ›ãŒååˆ†ã«è€ƒæ…®ã•ã‚Œã‚‹ã‚ˆã†ãªè»¢å‹¤ä½“åˆ¶",
        "internal_mobility": "è‡ªèº«ã®å¸Œæœ›ãŒååˆ†ã«è€ƒæ…®ã•ã‚Œã‚‹ã‚ˆã†ãªç¤¾å†…ç•°å‹•ä½“åˆ¶"
    },
    "Compensation & Recognition": {
        "overtime_pay": "æ®‹æ¥­ã—ãŸã‚‰ãã®åˆ†ã—ã£ã‹ã‚Šçµ¦ä¸ãŒæ”¯æ‰•ã‚ã‚Œã‚‹",
        "fair_evaluation": "è‡ªèº«ã®è¡Œã£ãŸä»•äº‹ãŒæ­£å½“ã«è©•ä¾¡ã•ã‚Œã‚‹",
        "promotion": "æˆæœã«å¿œã˜ã¦æ—©æœŸã®æ˜‡çµ¦ãƒ»æ˜‡æ ¼ãŒæœ›ã‚ã‚‹",
        "benefits": "å……å®Ÿã—ãŸç¦åˆ©åšç”Ÿ"
    },
    "Workload & Stress": {
        "workload": "è‡ªåˆ†ã®ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ¼ã«åˆã£ãŸé‡ã®ä»•äº‹ã§åƒã‘ã‚‹",
        "physical_load": "ä»•äº‹å†…å®¹ã‚„é‡ã«å¯¾ã™ã‚‹èº«ä½“çš„ãªè² è·ãŒå°‘ãªã„",
        "mental_load": "ä»•äº‹å†…å®¹ã‚„é‡ã«å¯¾ã™ã‚‹ç²¾ç¥çš„ãªè² è·ãŒå°‘ãªã„",
        "achievable_goals": "é”æˆå¯èƒ½æ€§ãŒè¦‹è¾¼ã¾ã‚Œã‚‹ç›®æ¨™ã‚„ãƒãƒ«ãƒ"
    },
    "Growth & Development": {
        "specialized_skills": "å°‚é–€çš„ãªã‚¹ã‚­ãƒ«ã‚„æŠ€è¡“ãƒ»çŸ¥è­˜ã‚„çµŒé¨“ã®ç²å¾—",
        "general_skills": "æ±ç”¨çš„ãªã‚¹ã‚­ãƒ«ï¼ˆã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³èƒ½åŠ›ã‚„è«–ç†çš„æ€è€ƒåŠ›ãªã©ï¼‰ã®ç²å¾—",
        "training": "æ•´ã£ãŸæ•™è‚²ä½“åˆ¶",
        "career_path": "è‡ªåˆ†ã«åˆã£ãŸå°†æ¥ã®ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹è¨­è¨ˆ",
        "career_match": "å°†æ¥è‡ªåˆ†ã®ãªã‚ŠãŸã„æ–¹å‘æ€§ã¨ãƒãƒƒãƒã—ãŸä»•äº‹",
        "role_models": "èº«è¿‘ã«ãƒ­ãƒ¼ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãªã‚‹ã‚ˆã†ãªäººãŒã„ã‚‹ç’°å¢ƒ"
    },
    "Job Satisfaction": {
        "pride_in_work": "èª‡ã‚Šã‚„ãƒ—ãƒ©ã‚¤ãƒ‰ã‚’æŒã¦ã‚‹ã‚ˆã†ãªä»•äº‹å†…å®¹",
        "social_contribution": "ç¤¾ä¼šã«å¯¾ã—ã¦è²¢çŒ®å®Ÿæ„Ÿã‚’æŒã¦ã‚‹ã‚ˆã†ãªä»•äº‹",
        "job_fulfillment": "ã‚„ã‚ŠãŒã„ã‚’æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ãªä»•äº‹",
        "autonomy": "è‡ªåˆ†ã®åˆ¤æ–­ã§é€²ã‚ã‚‰ã‚Œã‚‹è£é‡ã®ã‚ã‚‹ä»•äº‹",
        "sense_of_growth": "æˆé•·å®Ÿæ„Ÿã‚’æ„Ÿã˜ã‚‰ã‚Œã‚‹ã‚ˆã†ãªä»•äº‹",
        "sense_of_achievement": "é”æˆæ„Ÿã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ãªä»•äº‹",
        "impactful_work": "è¦æ¨¡ã®å¤§ããªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„ä»•äº‹",
        "use_of_strengths": "è‡ªåˆ†ã®å¼·ã¿ã‚’æ´»ã‹ã›ã‚‹ã‚ˆã†ãªä»•äº‹"
    },
    "Relationships & Culture": {
        "relationships": "äººé–“é–¢ä¿‚ãŒè‰¯å¥½ãªç’°å¢ƒ",
        "harassment_free": "ã‚»ã‚¯ãƒãƒ©ã‚„ãƒ‘ãƒ¯ãƒãƒ©ãŒãªã„ã‚ˆã†ãªç’°å¢ƒ",
        "culture_fit": "è‡ªèº«ã®ä¾¡å€¤è¦³ã‚„è€ƒãˆæ–¹ã¨å…±æ„Ÿã§ãã‚‹ã‚ˆã†ãªä¼šç¤¾ã®ç¤¾é¢¨ã‚„æ–‡åŒ–",
        "open_communication": "æ„è¦‹ã‚„è€ƒãˆæ–¹ãªã©ã«ã¤ã„ã¦è‡ªç”±ã«è¨€ã„åˆãˆã‚‹é¢¨é€šã—ã®è‰¯ã„ç’°å¢ƒ",
        "learning_culture": "ç¤¾å†…ã§ç›¸äº’ã«æ•™ãˆãŸã‚Šãƒ»å­¦ã³åˆã£ãŸã‚Šã™ã‚‹ã‚ˆã†ãªç’°å¢ƒ",
        "work_environment": "åƒãã‚„ã™ã„ä»•äº‹ç’°å¢ƒã‚„ã‚ªãƒ•ã‚£ã‚¹ç’°å¢ƒ",
        "women_support": "å¥³æ€§ãŒåƒãã‚„ã™ã„ç’°å¢ƒ"
    },
    "Company & Business": {
        "company_stability": "äº‹æ¥­åŸºç›¤ã®å®‰å¿ƒæ„Ÿ",
        "management_strategy": "ä¿¡é ¼ã§ãã‚‹çµŒå–¶æˆ¦ç•¥ã‚„æˆ¦è¡“ã®å®Ÿè¡Œ",
        "competitive_edge": "åŒæ¥­ä»–ç¤¾ã¨æ¯”è¼ƒã—ãŸäº‹æ¥­å†…å®¹ã®ç«¶åˆå„ªä½æ€§ã‚„ç‹¬è‡ªæ€§",
        "brand_power": "ãƒ–ãƒ©ãƒ³ãƒ‰åŠ›ã‚„çŸ¥ååº¦",
        "mission_vision_fit": "ä¼šç¤¾ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ»ãƒãƒªãƒ¥ãƒ¼",
        "compliance": "æ³•ä»¤éµå®ˆãŒæ•´ã£ãŸç¤¾å†…ä½“åˆ¶"
    }
}

# ã‚«ãƒ©ãƒ åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Ÿéš›ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰
COLUMN_MAPPING = {
    'å…¥ç¤¾å¹´åº¦ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚â€»2019å¹´å…¥ç¤¾ã®å ´åˆã«ã¯ã€2019ã¨ãŠç­”ãˆãã ã•ã„ã€‚': 'start_year',
    'æ¦‚ç®—å¹´åã‚’æ•™ãˆã¦ãã ã•ã„ã€‚450ä¸‡å††ã®å ´åˆã«ã¯ã€450ã¨åŠè§’ã§ãŠç­”ãˆãã ã•ã„ã€‚': 'annual_salary',
    '1ãƒ¶æœˆå½“ãŸã‚Šã®å¹³å‡æ®‹æ¥­æ™‚é–“ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆæ®‹æ¥­æ™‚é–“ãŒæœˆ100æ™‚é–“ã»ã©ã‚ã‚‹æ–¹ã¯100ã¨ãŠç­”ãˆãã ã•ã„ï¼‰': 'avg_monthly_overtime',
    '1å¹´é–“å½“ãŸã‚Šã®å¹³å‡æœ‰çµ¦ä¼‘æš‡å–å¾—ç‡ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆå…¨ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã‚Œã°100ã€80%ã»ã©åˆ©ç”¨ã•ã‚Œã¦ã„ã‚Œã°80ã¨ãŠç­”ãˆãã ã•ã„ã€‚ï¼‰': 'paid_leave_usage_rate',
    'ç·åˆè©•ä¾¡ï¼šè‡ªåˆ†ã®è¦ªã—ã„å‹äººã‚„å®¶æ—ã«å¯¾ã—ã¦ã€ã“ã®ä¼šç¤¾ã¸ã®è»¢è·ãƒ»å°±è·ã‚’ã©ã®ç¨‹åº¦å‹§ã‚ãŸã„ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ': 'recommend_score',
    'ç·åˆæº€è¶³åº¦ï¼šè‡ªç¤¾ã®ç¾åœ¨ã®åƒãç’°å¢ƒã‚„æ¡ä»¶ã€å‘¨ã‚Šã®äººé–“é–¢ä¿‚ãªã©ã‚‚å«ã‚ã‚ãªãŸã¯ã©ã®ç¨‹åº¦æº€è¶³ã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ': 'overall_satisfaction',
    'ã‚ãªãŸã¯ã“ã®ä¼šç¤¾ã§ã“ã‚Œã‹ã‚‰ã‚‚é•·ãåƒããŸã„ã¨æ€ã‚ã‚Œã¾ã™ã‹ï¼Ÿ': 'long_term_intention',
    'æ´»èºè²¢çŒ®åº¦ï¼šç¾åœ¨ã®ä¼šç¤¾ã‚„æ‰€å±çµ„ç¹”ã§ã‚ãªãŸã¯ã©ã®ç¨‹åº¦ã€æ´»èºè²¢çŒ®ã§ãã¦ã„ã‚‹ã¨æ„Ÿã˜ã¾ã™ã‹ï¼Ÿ': 'sense_of_contribution'
}

@st.cache_data
def load_real_excel_data():
    """æ–°ã—ã„Excelãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã«å¯¾å¿œã—ãŸãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    try:
        # Streamlit Cloudå¯¾å¿œ: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®data.xlsxã‚’å„ªå…ˆ
        excel_paths = [
            'data.xlsx',  # Streamlit Cloudç”¨
            '/Users/sugayayoshiyuki/Desktop/æ¡ç”¨å¯è¦–åŒ–ã‚µãƒ¼ãƒ™ã‚¤/å¾“æ¥­å“¡èª¿æŸ».xlsx'  # ãƒ­ãƒ¼ã‚«ãƒ«ç”¨
        ]
        
        excel_path = None
        for path in excel_paths:
            if os.path.exists(path):
                excel_path = path
                break
        
        if excel_path is None:
            st.info("ğŸ“Š å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ¢ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™")
            return create_professional_dummy_data(), False
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        excel_file = pd.ExcelFile(excel_path)
        
        if 'Responses' in excel_file.sheet_names:
            # 1è¡Œç›®ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦èª­ã¿è¾¼ã¿
            df = pd.read_excel(excel_path, sheet_name='Responses', header=0)
            
            print(f"èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶: {df.shape}")
            
            # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ãªã„å ´åˆ
            if len(df) <= 1:
                st.error("âŒ å®Ÿãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df)}ä»¶ï¼‰")
                st.warning("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åˆ†æç”¨ã®ãƒ‡ãƒ¢ç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
                st.info("ğŸ“Š æ­£å¸¸ãªåˆ†æã«ã¯è¤‡æ•°è¡Œã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
                return create_professional_dummy_data(), False
            
            # åŸºæœ¬ã‚«ãƒ©ãƒ ã®æ­£è¦åŒ–
            df = df.rename(columns=COLUMN_MAPPING)
            
            # å®Ÿéš›ã®ã‚«ãƒ©ãƒ åã‚’ä½¿ç”¨ã—ãŸãƒãƒƒãƒ”ãƒ³ã‚°
            actual_column_mapping = {
                'ç·åˆè©•ä¾¡ï¼šè‡ªåˆ†ã®è¦ªã—ã„å‹äººã‚„å®¶æ—ã«å¯¾ã—ã¦ã€ã“ã®ä¼šç¤¾ã¸ã®è»¢è·ãƒ»å°±è·ã‚’ã©ã®ç¨‹åº¦å‹§ã‚ãŸã„ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ': 'recommend_score',
                'ç·åˆæº€è¶³åº¦ï¼šè‡ªç¤¾ã®ç¾åœ¨ã®åƒãç’°å¢ƒã‚„æ¡ä»¶ã€å‘¨ã‚Šã®äººé–“é–¢ä¿‚ãªã©ã‚‚å«ã‚ã‚ãªãŸã¯ã©ã®ç¨‹åº¦æº€è¶³ã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ': 'overall_satisfaction', 
                'ã‚ãªãŸã¯ã“ã®ä¼šç¤¾ã§ã“ã‚Œã‹ã‚‰ã‚‚é•·ãåƒããŸã„ã¨æ€ã‚ã‚Œã¾ã™ã‹ï¼Ÿ': 'long_term_intention',
                'æ´»èºè²¢çŒ®åº¦ï¼šç¾åœ¨ã®ä¼šç¤¾ã‚„æ‰€å±çµ„ç¹”ã§ã‚ãªãŸã¯ã©ã®ç¨‹åº¦ã€æ´»èºè²¢çŒ®ã§ãã¦ã„ã‚‹ã¨æ„Ÿã˜ã¾ã™ã‹ï¼Ÿ': 'sense_of_contribution',
                'å…¥ç¤¾å¹´åº¦ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚â€»2019å¹´å…¥ç¤¾ã®å ´åˆã«ã¯ã€2019ã¨ãŠç­”ãˆãã ã•ã„ã€‚': 'start_year',
                'æ¦‚ç®—å¹´åã‚’æ•™ãˆã¦ãã ã•ã„ã€‚450ä¸‡å††ã®å ´åˆã«ã¯ã€450ã¨åŠè§’ã§ãŠç­”ãˆãã ã•ã„ã€‚': 'annual_salary',
                '1ãƒ¶æœˆå½“ãŸã‚Šã®å¹³å‡æ®‹æ¥­æ™‚é–“ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆæ®‹æ¥­æ™‚é–“ãŒæœˆ100æ™‚é–“ã»ã©ã‚ã‚‹æ–¹ã¯100ã¨ãŠç­”ãˆãã ã•ã„ï¼‰': 'avg_monthly_overtime',
                '1å¹´é–“å½“ãŸã‚Šã®å¹³å‡æœ‰çµ¦ä¼‘æš‡å–å¾—ç‡ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆå…¨ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã‚Œã°100ã€80%ã»ã©åˆ©ç”¨ã•ã‚Œã¦ã„ã‚Œã°80ã¨ãŠç­”ãˆãã ã•ã„ã€‚ï¼‰': 'paid_leave_usage_rate',
                'é›‡ç”¨å½¢æ…‹': 'employment_type',
                'æ‰€å±äº‹æ¥­éƒ¨': 'department',
                'å½¹è·': 'position',
                'è·ç¨®': 'job_type',
                'æœ€ã‚‚æœŸå¾…ãŒé«˜ã„é …ç›®ã«ã¤ã„ã¦ã‚ãªãŸãŒæœŸå¾…ã—ã¦ã„ã‚‹ã¨å›ç­”ã—ãŸé …ç›®ã®ä¸­ã§æœ€ã‚‚ã“ã®ä¼šç¤¾ã«æœŸå¾…ã—ã¦ã„ã‚‹ã“ã¨ã«ã¤ã„ã¦ã€å…·ä½“çš„ã«ã”è¨˜è¼‰ãã ã•ã„ã€‚ã©ã®ã‚ˆã†ãªå†…å®¹ãŒæº€ãŸã›ã‚‹ã¨ã‚ãªãŸã®æœŸå¾…ã‚’å¤§ããä¸Šå›ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã‹æ•™ãˆã¦ã„ãŸã ã‘ã‚‹å¹¸ã„ã§ã™ã€‚': 'expectation_comments',
                'æœ€ã‚‚æº€è¶³åº¦ãŒé«˜ã„é …ç›®ã«ã¤ã„ã¦ã‚ãªãŸãŒä»Šã®ä¼šç¤¾ã«æº€è¶³ã—ã¦ã„ã‚‹ã¨å›ç­”ã—ãŸé …ç›®ã®ä¸­ã§æœ€ã‚‚ã“ã®ä¼šç¤¾ã«æº€è¶³ãƒ»è©•ä¾¡ã—ã¦ã„ã‚‹å†…å®¹ã«ã¤ã„ã¦ã€å…·ä½“çš„ã«æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚': 'satisfaction_comments',
                'æº€è¶³åº¦ãŒä½ã„é …ç›®ã«ã¤ã„ã¦ã‚ãªãŸãŒä»Šã®ä¼šç¤¾ã«æº€è¶³ã—ã¦ã„ãªã„ã¨å›ç­”ã—ãŸé …ç›®ã®ä¸­ã§ã€å…·ä½“çš„ã«è‡ªç¤¾ã®ã©ã®ã‚ˆã†ãªç‚¹ã«å¯¾ã—ã¦ãã®ã‚ˆã†ã«æ„Ÿã˜ã‚‰ã‚ŒãŸã®ã‹æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚': 'dissatisfaction_comments'
            }
            
            # ã‚«ãƒ©ãƒ åã‚’æ­£è¦åŒ–
            df = df.rename(columns=actual_column_mapping)
            
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã¨å¤‰æ›
            numeric_columns = ['recommend_score', 'overall_satisfaction', 'long_term_intention', 'sense_of_contribution',
                             'start_year', 'annual_salary', 'avg_monthly_overtime', 'paid_leave_usage_rate']
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # æœŸå¾…åº¦é …ç›®ã®è­˜åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
            expectation_patterns = {
                'å‹¤å‹™æ™‚é–“': 'work_hours',
                'ä¼‘æ—¥ä¼‘æš‡ãŒã¡ã‚ƒã‚“ã¨å–ã‚Œã‚‹': 'holidays',
                'æœ‰çµ¦ä¼‘æš‡ãŒã¡ã‚ƒã‚“ã¨å–ã‚Œã‚‹': 'paid_leave',
                'æŸ”è»Ÿãªå‹¤å‹™ä½“ç³»': 'flex_work',
                'è‡ªå®…ã‹ã‚‰é©åˆ‡ãªè·é›¢': 'commute',
                'è»¢å‹¤ä½“åˆ¶': 'job_transfer',
                'ç¤¾å†…ç•°å‹•': 'internal_mobility',
                'æ®‹æ¥­ä»£': 'overtime_pay',
                'ä»•äº‹é‡': 'workload',
                'èº«ä½“çš„è² è·': 'physical_load',
                'ç²¾ç¥çš„è² è·': 'mental_load',
                'ç¦åˆ©åšç”Ÿ': 'benefits',
                'æ­£å½“ã«è©•ä¾¡': 'fair_evaluation',
                'æ˜‡çµ¦ãƒ»æ˜‡æ ¼': 'promotion',
                'ç›®æ¨™ã‚„ãƒãƒ«ãƒ': 'achievable_goals',
                'å°‚é–€çš„ãªã‚¹ã‚­ãƒ«': 'specialized_skills',
                'æ±ç”¨çš„ãªã‚¹ã‚­ãƒ«': 'general_skills',
                'æ•™è‚²ä½“åˆ¶': 'training',
                'ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹': 'career_path',
                'å°†æ¥.*ãƒãƒƒãƒ': 'career_match',
                'ãƒ­ãƒ¼ãƒ«ãƒ¢ãƒ‡ãƒ«': 'role_models',
                'èª‡ã‚Š.*ãƒ—ãƒ©ã‚¤ãƒ‰': 'pride_in_work',
                'ç¤¾ä¼š.*è²¢çŒ®': 'social_contribution',
                'ã‚„ã‚ŠãŒã„': 'job_fulfillment',
                'è£é‡': 'autonomy',
                'æˆé•·å®Ÿæ„Ÿ': 'sense_of_growth',
                'é”æˆæ„Ÿ': 'sense_of_achievement',
                'å¤§ããª.*ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ': 'impactful_work',
                'å¼·ã¿.*æ´»ã‹ã™': 'use_of_strengths',
                'äººé–“é–¢ä¿‚': 'relationships',
                'ãƒãƒ©ã‚¹ãƒ¡ãƒ³ãƒˆ': 'harassment_free',
                'ç¤¾é¢¨.*æ–‡åŒ–': 'culture_fit',
                'é¢¨é€šã—': 'open_communication',
                'ç›¸äº’.*å­¦ã³': 'learning_culture',
                'äº‹æ¥­åŸºç›¤': 'company_stability',
                'çµŒå–¶æˆ¦ç•¥': 'management_strategy',
                'ç«¶åˆå„ªä½æ€§': 'competitive_edge',
                'ãƒ–ãƒ©ãƒ³ãƒ‰åŠ›': 'brand_power',
                'ãƒŸãƒƒã‚·ãƒ§ãƒ³.*ãƒãƒªãƒ¥ãƒ¼': 'mission_vision_fit',
                'æ³•ä»¤éµå®ˆ': 'compliance',
                'ã‚ªãƒ•ã‚£ã‚¹ç’°å¢ƒ': 'work_environment',
                'å¥³æ€§.*åƒãã‚„ã™ã„': 'women_support'
            }
            
            # æœŸå¾…åº¦ãƒ»æº€è¶³åº¦ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            expectation_columns = {}
            satisfaction_columns = {}
            
            for col in df.columns:
                col_str = str(col)
                
                # æœŸå¾…åº¦é …ç›®ã®è­˜åˆ¥
                if 'ä»Šã®è·å ´ã«ã¯æœŸå¾…' in col_str or 'æœŸå¾…ã—ã¦ã„ãªã„' in col_str:
                    for pattern, key in expectation_patterns.items():
                        if re.search(pattern, col_str):
                            expectation_columns[col] = f'{key}_expectation'
                            break
                
                # æº€è¶³åº¦é …ç›®ã®è­˜åˆ¥  
                elif 'æº€è¶³ã—ã¦ã„ãªã„' in col_str or 'æº€è¶³ã—ã¦ã„ã‚‹' in col_str:
                    for pattern, key in expectation_patterns.items():
                        if re.search(pattern, col_str):
                            satisfaction_columns[col] = f'{key}_satisfaction'
                            break
            
            # æœŸå¾…åº¦ãƒ»æº€è¶³åº¦ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            for original_col, new_col in expectation_columns.items():
                if original_col in df.columns:
                    df[new_col] = pd.to_numeric(df[original_col], errors='coerce')
            
            for original_col, new_col in satisfaction_columns.items():
                if original_col in df.columns:
                    df[new_col] = pd.to_numeric(df[original_col], errors='coerce')
            
            print(f"å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
            print(f"æœŸå¾…åº¦é …ç›®æ•°: {len(expectation_columns)}")
            print(f"æº€è¶³åº¦é …ç›®æ•°: {len(satisfaction_columns)}")
            
            return df, True
        else:
            st.warning("'Responses'ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return create_professional_dummy_data(), False
            
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return create_professional_dummy_data(), False

@st.cache_data
def create_professional_dummy_data():
    """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    np.random.seed(42)
    n_employees = 180
    
    # ã‚ˆã‚Šç¾å®Ÿçš„ãªåŸºæœ¬ãƒ‡ãƒ¼ã‚¿
    data = pd.DataFrame({
        'employee_id': range(1, n_employees + 1),
        'start_year': np.random.choice(range(2018, 2025), n_employees, p=[0.08, 0.12, 0.15, 0.20, 0.18, 0.15, 0.12]),
        'annual_salary': np.random.choice([350, 400, 450, 500, 550, 600, 650, 700, 800, 900, 1000, 1200], 
                                        n_employees, p=[0.05, 0.1, 0.15, 0.2, 0.15, 0.1, 0.08, 0.07, 0.05, 0.03, 0.015, 0.005]),
        'avg_monthly_overtime': np.random.choice([0, 5, 10, 15, 20, 25, 30, 40, 50, 60, 80], 
                                               n_employees, p=[0.05, 0.1, 0.15, 0.2, 0.2, 0.15, 0.08, 0.04, 0.02, 0.008, 0.002]),
        'paid_leave_usage_rate': np.random.choice([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 
                                                n_employees, p=[0.02, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.15, 0.04, 0.01])
    })
    
    # NPSï¼ˆ0-10ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    data['recommend_score'] = np.random.choice(range(0, 11), n_employees, 
                                             p=[0.02, 0.03, 0.05, 0.08, 0.12, 0.15, 0.18, 0.15, 0.12, 0.08, 0.02])
    
    # ç·åˆçš„ãªè©•ä¾¡ï¼ˆ1-5ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    data['overall_satisfaction'] = np.random.choice(range(1, 6), n_employees, p=[0.05, 0.15, 0.35, 0.35, 0.1])
    data['long_term_intention'] = np.random.choice(range(1, 6), n_employees, p=[0.1, 0.2, 0.3, 0.3, 0.1])
    data['sense_of_contribution'] = np.random.choice(range(1, 6), n_employees, p=[0.05, 0.1, 0.25, 0.45, 0.15])
    
    # å„é …ç›®ã®æº€è¶³åº¦ãƒ»æœŸå¾…åº¦ãƒ‡ãƒ¼ã‚¿
    all_items = []
    for category, items in SURVEY_CATEGORIES.items():
        all_items.extend(items.keys())
    
    for item in all_items:
        # æº€è¶³åº¦ï¼ˆç·åˆæº€è¶³åº¦ã¨ç›¸é–¢ï¼‰
        base_satisfaction = data['overall_satisfaction'].values
        noise = np.random.normal(0, 0.7, n_employees)
        satisfaction_scores = (base_satisfaction + noise).clip(1, 5).round().astype(int)
        data[f'{item}_satisfaction'] = satisfaction_scores
        
        # æœŸå¾…åº¦ï¼ˆæº€è¶³åº¦ã‚ˆã‚Šè‹¥å¹²é«˜ã‚ï¼‰
        expectation_scores = (satisfaction_scores + np.random.normal(0.3, 0.5, n_employees)).clip(1, 5).round().astype(int)
        data[f'{item}_expectation'] = expectation_scores
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
    positive_comments = [
        'è·å ´ã®äººé–“é–¢ä¿‚ãŒè‰¯å¥½ã§åƒãã‚„ã™ã„ç’°å¢ƒã§ã™',
        'ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ãŒå°å…¥ã•ã‚Œã¦ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸ',
        'ä¸Šå¸ã‹ã‚‰ã®ã‚µãƒãƒ¼ãƒˆãŒå……å®Ÿã—ã¦ã„ã¦æˆé•·ã§ãã‚‹ç’°å¢ƒã§ã™',
        'ç¦åˆ©åšç”ŸãŒå……å®Ÿã—ã¦ã„ã¦å®‰å¿ƒã—ã¦åƒã‘ã¾ã™',
        'æŒ‘æˆ¦çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å‚åŠ ã§ãã¦æˆé•·å®Ÿæ„ŸãŒã‚ã‚Šã¾ã™',
        'ç¤¾å†…ç ”ä¿®åˆ¶åº¦ãŒæ•´ã£ã¦ã„ã¦ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã§ãã¾ã™',
        'ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹åˆ¶åº¦ãŒã‚ã‚Šè‡ªåˆ†ã®ãƒšãƒ¼ã‚¹ã§ä»•äº‹ãŒã§ãã¾ã™',
        'è©•ä¾¡åˆ¶åº¦ãŒé€æ˜ã§å…¬æ­£ãªè©•ä¾¡ã‚’å—ã‘ã‚‰ã‚Œã¾ã™'
    ]
    
    negative_comments = [
        'æ®‹æ¥­æ™‚é–“ãŒå¤šããƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Šã«ãã„',
        'æ˜‡é€²ãƒ»æ˜‡æ ¼ã®åŸºæº–ãŒä¸é€æ˜ã§å°†æ¥ãŒè¦‹ãˆã«ãã„',
        'æ¥­å‹™é‡ãŒå¤šã™ãã¦ç²¾ç¥çš„ãªè² æ‹…ãŒå¤§ãã„',
        'æœ‰çµ¦ä¼‘æš‡ãŒå–ã‚Šã«ãã„è·å ´ç’°å¢ƒã§ã™',
        'ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä¸è¶³ã§æƒ…å ±å…±æœ‰ãŒä¸ååˆ†',
        'çµ¦ä¸æ°´æº–ãŒä»–ç¤¾ã¨æ¯”ã¹ã¦ä½ã„ã¨æ„Ÿã˜ã¾ã™',
        'æ•™è‚²ä½“åˆ¶ãŒä¸ååˆ†ã§ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ãŒå›°é›£',
        'è·å ´ã®è¨­å‚™ãŒå¤ãä½œæ¥­åŠ¹ç‡ãŒæ‚ªã„'
    ]
    
    neutral_comments = [
        'å…¨ä½“çš„ã«ã¯æ™®é€šã®è·å ´ã ã¨æ€ã„ã¾ã™',
        'è‰¯ã„é¢ã¨æ‚ªã„é¢ãŒä¸¡æ–¹ã‚ã‚Šã¾ã™',
        'å¯ã‚‚ãªãä¸å¯ã‚‚ãªã„è·å ´ç’°å¢ƒã§ã™',
        'æ”¹å–„ã®ä½™åœ°ã¯ã‚ã‚Šã¾ã™ãŒæ‚ªãã¯ã‚ã‚Šã¾ã›ã‚“'
    ]
    
    # æº€è¶³åº¦ã«å¿œã˜ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†é…
    comments = []
    expectation_detail_comments = []
    
    for i in range(n_employees):
        satisfaction = data.loc[i, 'overall_satisfaction']
        
        if satisfaction >= 4:
            comment = np.random.choice(positive_comments)
            exp_comment = 'ã•ã‚‰ãªã‚‹æˆé•·æ©Ÿä¼šã¨ã‚­ãƒ£ãƒªã‚¢é–‹ç™ºæ”¯æ´ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™'
        elif satisfaction <= 2:
            comment = np.random.choice(negative_comments)
            exp_comment = 'ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ã®æ”¹å–„ã¨åŠ´åƒç’°å¢ƒã®æ•´å‚™ã‚’å¼·ãå¸Œæœ›ã—ã¾ã™'
        else:
            comment = np.random.choice(neutral_comments)
            exp_comment = 'è·å ´ç’°å¢ƒã®æ”¹å–„ã¨æ¥­å‹™åŠ¹ç‡åŒ–ã‚’æœŸå¾…ã—ã¦ã„ã¾ã™'
        
        comments.append(comment)
        expectation_detail_comments.append(exp_comment)
    
    data['satisfaction_comments'] = comments
    data['dissatisfaction_comments'] = [c for c in comments if any(neg in c for neg in ['æ®‹æ¥­', 'è² æ‹…', 'ä¸é€æ˜', 'å›°é›£', 'ä¸ååˆ†', 'ä½ã„'])]
    data['expectation_comments'] = expectation_detail_comments
    
    # dissatisfaction_commentsãŒç©ºã®å ´åˆã¯ã€ãƒ€ãƒŸãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
    if len(data['dissatisfaction_comments']) == 0:
        data.loc[:min(30, len(data)-1), 'dissatisfaction_comments'] = negative_comments[:min(31, len(data))]
    
    return data

@st.cache_data
def calculate_professional_kpis(data, is_real_data):
    """æ›´æ–°ã•ã‚ŒãŸKPIè¨ˆç®—"""
    # å‹¤ç¶šå¹´æ•°è¨ˆç®—
    current_year = datetime.now().year
    if 'start_year' in data.columns:
        data['work_years'] = current_year - data['start_year']
    else:
        data['work_years'] = 3.5
    
    # NPSè¨ˆç®—ï¼ˆ1-5ã‚¹ã‚±ãƒ¼ãƒ«ã‚’0-10ã«å¤‰æ›ï¼‰
    if 'recommend_score' in data.columns and not data['recommend_score'].isna().all():
        recommend_scaled = data['recommend_score'] * 2  # 1-5 â†’ 2-10
        promoters = len(recommend_scaled[recommend_scaled >= 9])
        detractors = len(recommend_scaled[recommend_scaled <= 6])
        nps = ((promoters - detractors) / len(data)) * 100
        avg_recommend_score = data['recommend_score'].mean()
    else:
        nps = 0
        avg_recommend_score = 0
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
    category_stats = {}
    for category, items in SURVEY_CATEGORIES.items():
        satisfaction_values = []
        expectation_values = []
        
        for item_key in items.keys():
            sat_col = f'{item_key}_satisfaction'
            exp_col = f'{item_key}_expectation'
            
            if sat_col in data.columns and not data[sat_col].isna().all():
                satisfaction_values.append(data[sat_col].mean())
            if exp_col in data.columns and not data[exp_col].isna().all():
                expectation_values.append(data[exp_col].mean())
        
        if satisfaction_values:
            category_stats[category] = {
                'satisfaction': np.mean(satisfaction_values),
                'expectation': np.mean(expectation_values) if expectation_values else 0,
                'gap': np.mean(satisfaction_values) - np.mean(expectation_values) if expectation_values else 0
            }
    
    # å€‹åˆ¥é …ç›®çµ±è¨ˆ
    item_stats = {}
    for category, items in SURVEY_CATEGORIES.items():
        for item_key, item_name in items.items():
            sat_col = f'{item_key}_satisfaction'
            exp_col = f'{item_key}_expectation'
            
            if sat_col in data.columns and not data[sat_col].isna().all():
                item_stats[item_name] = {
                    'satisfaction': data[sat_col].mean(),
                    'expectation': data[exp_col].mean() if exp_col in data.columns and not data[exp_col].isna().all() else 0,
                    'gap': data[sat_col].mean() - data[exp_col].mean() if exp_col in data.columns and not data[exp_col].isna().all() else 0
                }
    
    # å®‰å…¨ã«KPIã‚’è¨ˆç®—
    def safe_mean(col_name, default=0):
        return data[col_name].mean() if col_name in data.columns and not data[col_name].isna().all() else default
    
    return {
        'total_employees': len(data),
        'nps': nps,
        'avg_recommend_score': avg_recommend_score,
        'avg_satisfaction': safe_mean('overall_satisfaction', 3.5),
        'avg_contribution': safe_mean('sense_of_contribution', 3.5),
        'avg_long_term_intention': safe_mean('long_term_intention', 3.5),
        'avg_salary': safe_mean('annual_salary', 500),
        'median_salary': data['annual_salary'].median() if 'annual_salary' in data.columns and not data['annual_salary'].isna().all() else 500,
        'avg_overtime': safe_mean('avg_monthly_overtime', 25),
        'avg_leave_usage': safe_mean('paid_leave_usage_rate', 60),
        'avg_work_years': safe_mean('work_years', 3.5),
        'category_stats': category_stats,
        'item_stats': item_stats,
        'is_real_data': is_real_data,
        'data_source': "Real Survey Data (150 responses)" if is_real_data else "Demo Data"
    }

def get_kpi_color_class(value, thresholds):
    """KPIã®å€¤ã«åŸºã¥ã„ã¦è‰²ã‚¯ãƒ©ã‚¹ã‚’è¿”ã™"""
    if value >= thresholds['good']:
        return 'kpi-positive'
    elif value <= thresholds['bad']:
        return 'kpi-negative'
    else:
        return 'kpi-warning'

def show_professional_kpi_overview(data, kpis):
    """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªKPIæ¦‚è¦è¡¨ç¤º"""
    # ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>Employee Survey Dashboard</h1>
        <p>Comprehensive analysis of employee satisfaction and engagement metrics</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¡¨ç¤º
    data_source = kpis.get('data_source', "Demo Data")
    st.markdown(f"**Data Source:** {data_source} | **Sample Size:** {kpis['total_employees']} employees")
    
    # KPIã‚«ãƒ¼ãƒ‰
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        nps_class = get_kpi_color_class(kpis['nps'], {'good': 10, 'bad': -10})
        st.markdown(f"""
        <div class="kpi-card {nps_class}">
            <div class="kpi-title">Employee NPS</div>
            <div class="kpi-value">{kpis['nps']:.1f}</div>
            <div class="kpi-description">Net Promoter Score</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        satisfaction_class = get_kpi_color_class(kpis['avg_satisfaction'], {'good': 4.0, 'bad': 2.5})
        st.markdown(f"""
        <div class="kpi-card {satisfaction_class}">
            <div class="kpi-title">Overall Satisfaction</div>
            <div class="kpi-value">{kpis['avg_satisfaction']:.2f}/5</div>
            <div class="kpi-description">Average satisfaction score</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        contribution_class = get_kpi_color_class(kpis['avg_contribution'], {'good': 4.0, 'bad': 2.5})
        st.markdown(f"""
        <div class="kpi-card {contribution_class}">
            <div class="kpi-title">Contribution Level</div>
            <div class="kpi-value">{kpis['avg_contribution']:.2f}/5</div>
            <div class="kpi-description">Self-assessed performance</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        retention_class = get_kpi_color_class(kpis['avg_long_term_intention'], {'good': 4.0, 'bad': 2.5})
        st.markdown(f"""
        <div class="kpi-card {retention_class}">
            <div class="kpi-title">Retention Intent</div>
            <div class="kpi-value">{kpis['avg_long_term_intention']:.2f}/5</div>
            <div class="kpi-description">Long-term commitment</div>
        </div>
        """, unsafe_allow_html=True)
    
    # ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹
    st.markdown("### Key Metrics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    metrics = [
        ("Average Salary", f"Â¥{kpis['avg_salary']:.0f}ä¸‡", f"Median: Â¥{kpis['median_salary']:.0f}ä¸‡"),
        ("Overtime Hours", f"{kpis['avg_overtime']:.1f}h", "Monthly average"),
        ("Leave Usage", f"{kpis['avg_leave_usage']:.1f}%", "Annual vacation usage"),
        ("Avg Tenure", f"{kpis['avg_work_years']:.1f}å¹´", "Years of service")
    ]
    
    for i, (title, value, desc) in enumerate(metrics):
        with [col1, col2, col3, col4][i]:
            st.markdown(f"""
            <div class="kpi-card">
                <div class="kpi-title">{title}</div>
                <div class="kpi-value">{value}</div>
                <div class="kpi-description">{desc}</div>
            </div>
            """, unsafe_allow_html=True)

def show_professional_category_analysis(data, kpis):
    """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚«ãƒ†ã‚´ãƒªåˆ†æ"""
    st.markdown('<div class="section-header"><h2>Category Analysis</h2></div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["Radar Analysis", "Category Ranking", "Gap Analysis"])
    
    with tab1:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        categories = list(kpis['category_stats'].keys())
        satisfaction_values = [kpis['category_stats'][cat]['satisfaction'] for cat in categories]
        expectation_values = [kpis['category_stats'][cat]['expectation'] for cat in categories]
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatterpolar(
            r=satisfaction_values,
            theta=categories,
            fill='toself',
            name='Satisfaction',
            line=dict(color='#3b82f6', width=3),
            fillcolor='rgba(59, 130, 246, 0.1)'
        ))
        
        fig.add_trace(go.Scatterpolar(
            r=expectation_values,
            theta=categories,
            fill='toself',
            name='Expectation',
            line=dict(color='#ef4444', width=3),
            fillcolor='rgba(239, 68, 68, 0.1)'
        ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 5],
                    tickfont=dict(size=10),
                    gridcolor='#e5e7eb'
                ),
                angularaxis=dict(
                    tickfont=dict(size=11, color='#374151')
                ),
                bgcolor='rgba(255, 255, 255, 0)'
            ),
            title=dict(
                text="Satisfaction vs Expectation by Category",
                font=dict(size=16, color='#1e293b')
            ),
            height=500,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=-0.1,
                xanchor="center",
                x=0.5
            ),
            paper_bgcolor='rgba(255, 255, 255, 0)',
            plot_bgcolor='rgba(255, 255, 255, 0)'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with tab2:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        category_df = pd.DataFrame({
            'Category': categories,
            'Satisfaction': satisfaction_values,
            'Expectation': expectation_values,
            'Gap': [kpis['category_stats'][cat]['gap'] for cat in categories]
        }).sort_values('Satisfaction', ascending=True)
        
        fig = px.bar(
            category_df,
            x='Satisfaction',
            y='Category',
            orientation='h',
            title='Category Satisfaction Ranking',
            color='Satisfaction',
            color_continuous_scale='RdYlGn',
            range_color=[1, 5]
        )
        
        fig.update_layout(
            height=400,
            title_font_size=16,
            paper_bgcolor='rgba(255, 255, 255, 0)',
            plot_bgcolor='rgba(255, 255, 255, 0)'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ã‚«ãƒ†ã‚´ãƒªè©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
        st.markdown("#### Category Details")
        category_display = category_df.round(2)
        st.dataframe(category_display, use_container_width=True, hide_index=True)
    
    with tab3:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        # ã‚®ãƒ£ãƒƒãƒ—åˆ†æ
        gap_df = pd.DataFrame({
            'Category': categories,
            'Satisfaction': satisfaction_values,
            'Expectation': expectation_values,
            'Gap': [kpis['category_stats'][cat]['gap'] for cat in categories]
        })
        
        fig = px.scatter(
            gap_df,
            x='Satisfaction',
            y='Expectation',
            size=np.abs(gap_df['Gap']) + 0.1,
            color='Gap',
            hover_name='Category',
            title='Expectation vs Satisfaction Gap Analysis',
            color_continuous_scale='RdYlGn',
            range_x=[1, 5],
            range_y=[1, 5]
        )
        
        # å¯¾è§’ç·šè¿½åŠ 
        fig.add_shape(
            type="line", x0=1, y0=1, x1=5, y1=5,
            line=dict(color="gray", width=2, dash="dash"),
        )
        
        fig.update_layout(
            height=500,
            title_font_size=16,
            paper_bgcolor='rgba(255, 255, 255, 0)',
            plot_bgcolor='rgba(255, 255, 255, 0)'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

def show_professional_detailed_analysis(data, kpis):
    """è©³ç´°åˆ†æè¡¨ç¤º"""
    st.markdown('<div class="section-header"><h2>Detailed Item Analysis</h2></div>', unsafe_allow_html=True)
    
    # ã‚«ãƒ†ã‚´ãƒªé¸æŠ
    selected_category = st.selectbox(
        "Select category for detailed analysis:",
        list(SURVEY_CATEGORIES.keys()),
        index=0
    )
    
    if selected_category:
        st.markdown(f"### {selected_category} - Detailed Analysis")
        
        category_items = SURVEY_CATEGORIES[selected_category]
        
        # é …ç›®åˆ¥æº€è¶³åº¦
        item_data = []
        for item_key, item_name in category_items.items():
            if f'{item_key}_satisfaction' in data.columns:
                satisfaction = data[f'{item_key}_satisfaction'].mean()
                expectation = data[f'{item_key}_expectation'].mean() if f'{item_key}_expectation' in data.columns else 0
                item_data.append({
                    'Item': item_name,
                    'Satisfaction': satisfaction,
                    'Expectation': expectation,
                    'Gap': satisfaction - expectation
                })
        
        if item_data:
            item_df = pd.DataFrame(item_data).sort_values('Satisfaction', ascending=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown('<div class="chart-container">', unsafe_allow_html=True)
                
                fig = px.bar(
                    item_df,
                    x='Satisfaction',
                    y='Item',
                    orientation='h',
                    title='Item Satisfaction Scores',
                    color='Satisfaction',
                    color_continuous_scale='RdYlGn',
                    range_color=[1, 5]
                )
                
                fig.update_layout(
                    height=400,
                    title_font_size=14,
                    paper_bgcolor='rgba(255, 255, 255, 0)',
                    plot_bgcolor='rgba(255, 255, 255, 0)'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="chart-container">', unsafe_allow_html=True)
                
                fig = px.scatter(
                    item_df,
                    x='Satisfaction',
                    y='Expectation',
                    size=np.abs(item_df['Gap']) + 0.1,
                    color='Gap',
                    hover_name='Item',
                    title='Satisfaction vs Expectation',
                    color_continuous_scale='RdYlGn',
                    range_x=[1, 5],
                    range_y=[1, 5]
                )
                
                fig.add_shape(
                    type="line", x0=1, y0=1, x1=5, y1=5,
                    line=dict(color="gray", width=2, dash="dash"),
                )
                
                fig.update_layout(
                    height=400,
                    title_font_size=14,
                    paper_bgcolor='rgba(255, 255, 255, 0)',
                    plot_bgcolor='rgba(255, 255, 255, 0)'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.markdown("#### Item Details")
            display_df = item_df.round(2)
            st.dataframe(display_df, use_container_width=True, hide_index=True)

def main():
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    color: white; padding: 1.5rem; border-radius: 12px; margin-bottom: 1.5rem; text-align: center;">
            <h3 style="margin: 0; color: white;">Employee Survey</h3>
            <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">Analytics Dashboard</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ãƒšãƒ¼ã‚¸é¸æŠ
        page = st.radio(
            "Navigation",
            ["Dashboard Overview", "Category Analysis", "Detailed Analysis", "Regression Analysis", "Text Mining", "ğŸ¤– AI Text Analysis"],
            index=0
        )
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        st.markdown("### Data Information")
        st.info("""
        This dashboard automatically loads real Excel data when available. 
        If no real data is found, it displays professional demo data for illustration purposes.
        """)
        
        # çµ±è¨ˆæƒ…å ±
        st.markdown("### Survey Metrics")
        st.markdown("""
        - **NPS Scale**: 0-10 (Net Promoter Score)
        - **Satisfaction Scale**: 1-5 (Likert Scale)
        - **Categories**: 7 main areas
        - **Total Items**: 55+ survey questions
        """)
        
        st.markdown("---")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
        st.markdown("### Filters")
        dept_filter = st.selectbox("Department", ["All Departments", "Sales", "Engineering", "Marketing", "HR", "Finance"])
        role_filter = st.selectbox("Role Level", ["All Roles", "Junior", "Mid", "Senior", "Manager", "Director"])
        
        st.caption("*Filters will be active when real data with demographic information is loaded")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    with st.spinner("Loading survey data..."):
        data, is_real_data = load_real_excel_data()
        kpis = calculate_professional_kpis(data, is_real_data)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çŠ¶æ³ã®è¡¨ç¤º
    if is_real_data:
        st.success(f"âœ… å®Ÿéš›ã®å¾“æ¥­å“¡èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ä¸­ï¼ˆ{len(data)}ä»¶ï¼‰")
        st.info("ğŸ“Š ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯æœ€æ–°ã®å¾“æ¥­å“¡èª¿æŸ»çµæœã‚’åæ˜ ã—ã¦ã„ã¾ã™")
    else:
        st.warning("âš ï¸ ãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ä¸­ - å®Ÿéš›ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚")
        st.info("ğŸ“ å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯æ­£ã—ã„Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„")
    
    # ãƒšãƒ¼ã‚¸è¡¨ç¤º
    if page == "Dashboard Overview":
        show_professional_kpi_overview(data, kpis)
    elif page == "Category Analysis":
        show_professional_category_analysis(data, kpis)
    elif page == "Detailed Analysis":
        show_professional_detailed_analysis(data, kpis)
    elif page == "Regression Analysis":
        show_professional_regression_analysis(data, kpis)
    elif page == "Text Mining":
        show_professional_text_mining(data, kpis)
    elif page == "ğŸ¤– AI Text Analysis":
        # AIãƒ†ã‚­ã‚¹ãƒˆåˆ†ææ©Ÿèƒ½ã‚’è¡¨ç¤º
        try:
            from text_analysis_ml import show_text_analysis_ml_page
            show_text_analysis_ml_page()
        except ImportError as e:
            st.error(f"AIãƒ†ã‚­ã‚¹ãƒˆåˆ†ææ©Ÿèƒ½ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.info("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆjanome, scikit-learnï¼‰ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def show_professional_regression_analysis(data, kpis):
    """é‡å›å¸°åˆ†æã‚’è¡¨ç¤º"""
    st.markdown('<div class="section-header"><h2>ğŸ”¬ Multiple Regression Analysis</h2></div>', unsafe_allow_html=True)
    st.markdown("ä¸»è¦æŒ‡æ¨™ã«å¯¾ã™ã‚‹æº€è¶³åº¦é …ç›®ã®å½±éŸ¿åŠ›ã‚’åˆ†æã—ã¾ã™")
    
    # ç›®çš„å¤‰æ•°ã®é¸æŠ
    target_options = {
        'eNPS (æ¨å¥¨åº¦)': 'recommend_score',
        'ç·åˆæº€è¶³åº¦': 'overall_satisfaction', 
        'å‹¤ç¶šæ„å‘': 'long_term_intention',
        'æ´»èºè²¢çŒ®åº¦': 'sense_of_contribution'
    }
    
    selected_target = st.selectbox(
        "ğŸ¯ åˆ†æå¯¾è±¡ï¼ˆç›®çš„å¤‰æ•°ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
        list(target_options.keys())
    )
    
    target_col = target_options[selected_target]
    
    if target_col not in data.columns:
        st.error(f"ç›®çš„å¤‰æ•° '{target_col}' ãŒãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    try:
        from sklearn.linear_model import LinearRegression
        from sklearn.preprocessing import StandardScaler
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import r2_score, mean_squared_error
        import scipy.stats as stats
        
        # èª¬æ˜å¤‰æ•°ï¼ˆæº€è¶³åº¦é …ç›®ï¼‰ã‚’æº–å‚™
        explanatory_vars = []
        var_names = []
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿ã®æº€è¶³åº¦é …ç›®ã‚’æ¤œç´¢
        satisfaction_patterns = [
            'è‡ªåˆ†ã«åˆã£ãŸå‹¤å‹™æ™‚é–“ã§åƒã‘ã‚‹',
            'ä¼‘æ—¥ä¼‘æš‡ãŒã¡ã‚ƒã‚“ã¨å–ã‚Œã‚‹', 
            'æœ‰çµ¦ä¼‘æš‡ãŒã¡ã‚ƒã‚“ã¨å–ã‚Œã‚‹',
            'æŸ”è»Ÿãªå‹¤å‹™ä½“ç³»',
            'äººé–“é–¢ä¿‚ãŒè‰¯å¥½ãª',
            'ä»•äº‹å†…å®¹ã‚„é‡ã«å¯¾ã™ã‚‹ç²¾ç¥çš„ãªè² è·',
            'å……å®Ÿã—ãŸç¦åˆ©åšç”Ÿ',
            'è‡ªèº«ã®è¡Œã£ãŸä»•äº‹ãŒæ­£å½“ã«è©•ä¾¡ã•ã‚Œã‚‹',
            'æˆæœã«å¿œã˜ã¦æ—©æœŸã®æ˜‡çµ¦ãƒ»æ˜‡æ ¼'
        ]
        
        for col in data.columns:
            col_str = str(col)
            # æº€è¶³åº¦é …ç›®ã‚’æ¤œç´¢ï¼ˆã€Œæº€è¶³ã—ã¦ã„ã‚‹ã€ã‚’å«ã‚€ã‚«ãƒ©ãƒ ï¼‰
            if any(pattern in col_str for pattern in satisfaction_patterns) and 'æº€è¶³ã—ã¦ã„ã‚‹' in col_str:
                explanatory_vars.append(col)
                # ç°¡æ½”ãªåå‰ã‚’æŠ½å‡º
                short_name = col_str.split('ï¼ˆ')[0].replace('æº€è¶³ã—ã¦ã„ã‚‹', '').replace('ã«ã¤ã„ã¦', '')
                var_names.append(short_name[:20])  # 20æ–‡å­—ã¾ã§
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯å¾“æ¥ã®æ–¹æ³•ã‚’ä½¿ç”¨
        if len(explanatory_vars) == 0 and hasattr(data, 'columns') and any('_satisfaction' in str(col) for col in data.columns):
            for category, items in SURVEY_CATEGORIES.items():
                for item_key, item_name in items.items():
                    sat_col = f'{item_key}_satisfaction'
                    if sat_col in data.columns:
                        explanatory_vars.append(sat_col)
                        var_names.append(item_name)
        
        if len(explanatory_vars) < 2:
            st.error("åˆ†æã«å¿…è¦ãªèª¬æ˜å¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        try:
            X = data[explanatory_vars]
            y = data[target_col]
            
            st.info(f"åˆ†æå¯¾è±¡: {len(explanatory_vars)}å€‹ã®èª¬æ˜å¤‰æ•°ã€{len(data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
            
        except KeyError as e:
            st.error(f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            st.info("åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ :")
            st.write(list(data.columns))
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤åŒ–ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        X_clean = X.copy()
        y_clean = y.copy()
        
        # æ•°å€¤åŒ–
        for col in X_clean.columns:
            X_clean[col] = pd.to_numeric(X_clean[col], errors='coerce')
        y_clean = pd.to_numeric(y_clean, errors='coerce')
        
        # æ¬ æå€¤å‡¦ç†
        X_clean = X_clean.fillna(X_clean.mean())
        y_clean = y_clean.fillna(y_clean.mean())
        
        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
        valid_mask = ~(X_clean.isna().any(axis=1) | y_clean.isna())
        X_final = X_clean[valid_mask]
        y_final = y_clean[valid_mask]
        
        if len(X_final) < 10:
            st.error(f"æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã§ã™ï¼ˆ{len(X_final)}ä»¶ï¼‰ã€‚åˆ†æã«ã¯æœ€ä½10ä»¶ãŒå¿…è¦ã§ã™ã€‚")
            return
            
        # é‡å›å¸°åˆ†æå®Ÿè¡Œ
        model = LinearRegression()
        model.fit(X_final, y_final)
        
        y_pred = model.predict(X_final)
        r2 = r2_score(y_final, y_pred)
        mse = mean_squared_error(y_final, y_pred)
        
        # çµæœè¡¨ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            <div class="kpi-card">
                <h3>ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½</h3>
                <p style="font-size: 1.5rem; font-weight: bold; color: #3b82f6;">
                    RÂ² = {r2:.3f}
                </p>
                <p>æ±ºå®šä¿‚æ•°ï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="kpi-card">
                <h3>ğŸ¯ RMSE</h3>
                <p style="font-size: 1.5rem; font-weight: bold; color: #10b981;">
                    {np.sqrt(mse):.3f}
                </p>
                <p>å¹³å‡äºŒä¹—èª¤å·®ã®å¹³æ–¹æ ¹</p>
            </div>
            """, unsafe_allow_html=True)
        
        # ä¿‚æ•°ã®é‡è¦åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        if len(var_names) == len(model.coef_):
            coefficients = pd.DataFrame({
                'Variable': var_names,
                'Coefficient': model.coef_,
                'Abs_Coefficient': np.abs(model.coef_)
            }).sort_values('Abs_Coefficient', ascending=True)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚«ãƒ©ãƒ åã‚’ä½¿ç”¨
            coefficients = pd.DataFrame({
                'Variable': [f'Var_{i}' for i in range(len(model.coef_))],
                'Coefficient': model.coef_,
                'Abs_Coefficient': np.abs(model.coef_)
            }).sort_values('Abs_Coefficient', ascending=True)
        
        fig = px.bar(
            coefficients.tail(15), 
            x='Coefficient', 
            y='Variable',
            orientation='h',
            title=f"{selected_target}ã¸ã®å½±éŸ¿åº¦ï¼ˆå›å¸°ä¿‚æ•°ï¼‰",
            color='Coefficient',
            color_continuous_scale='RdBu_r'
        )
        
        fig.update_layout(
            height=600,
            showlegend=False,
            template="plotly_white"
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è©³ç´°çµ±è¨ˆ
        with st.expander("ğŸ“‹ è©³ç´°çµ±è¨ˆ"):
            if len(var_names) == len(model.coef_):
                results_df = pd.DataFrame({
                    'é …ç›®': var_names,
                    'å›å¸°ä¿‚æ•°': model.coef_.round(4),
                    'çµ¶å¯¾å€¤': np.abs(model.coef_).round(4)
                }).sort_values('çµ¶å¯¾å€¤', ascending=False)
            else:
                results_df = pd.DataFrame({
                    'é …ç›®': [f'Variable_{i}' for i in range(len(model.coef_))],
                    'å›å¸°ä¿‚æ•°': model.coef_.round(4),
                    'çµ¶å¯¾å€¤': np.abs(model.coef_).round(4)
                }).sort_values('çµ¶å¯¾å€¤', ascending=False)
            
            st.dataframe(results_df, use_container_width=True)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            st.write(f"èª¬æ˜å¤‰æ•°æ•°: {len(explanatory_vars)}")
            st.write(f"ä½¿ç”¨ã—ãŸã‚«ãƒ©ãƒ : {explanatory_vars[:5]}...") # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
            
    except ImportError as e:
        st.error(f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        st.info("scikit-learn, scipy ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
    except Exception as e:
        st.error(f"å›å¸°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def show_professional_text_mining(data, kpis):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°ã‚’è¡¨ç¤º"""
    st.markdown('<div class="section-header"><h2>ğŸ“ Text Mining Analysis</h2></div>', unsafe_allow_html=True)
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    text_columns = []
    for col in data.columns:
        if 'comment' in col.lower() or 'ã‚³ãƒ¡ãƒ³ãƒˆ' in str(col):
            if data[col].notna().sum() > 0:
                text_columns.append(col)
    
    if not text_columns:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    selected_text_col = st.selectbox(
        "åˆ†æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆé …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„",
        text_columns
    )
    
    try:
        from collections import Counter
        import re
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        text_data = data[selected_text_col].dropna()
        
        if len(text_data) == 0:
            st.warning("é¸æŠã•ã‚ŒãŸé …ç›®ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        all_text = ' '.join(text_data.astype(str))
        
        # ãƒã‚¤ã‚ºæ–‡å­—ã‚’é™¤å»
        all_text = re.sub(r'[\n\r\t]+', ' ', all_text)  # æ”¹è¡Œã€ã‚¿ãƒ–ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«
        all_text = re.sub(r'[0-9ï¼-ï¼™]+', '', all_text)  # æ•°å­—ã‚’é™¤å»
        
        # æ—¥æœ¬èªã®å˜èªã‚’æŠ½å‡ºï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ï¼‰
        japanese_pattern = r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]{2,}'
        words = re.findall(japanese_pattern, all_text)
        
        # ä¸€èˆ¬çš„ãªã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å¤–
        stop_words = [
            'ã§ã™', 'ã§ã‚ã‚‹', 'ã§ã‚ã‚Š', 'ã‚ã‚Šã¾ã™', 'ã„ã¾ã™', 'ã—ã¾ã™', 'ã—ã¦ã„ã‚‹',
            'ã“ã¨', 'ã‚‚ã®', 'ã“ã®', 'ãã®', 'ã‚ã®', 'ã©ã®', 'ãªã©', 'ãªã©ã®',
            'ã“ã¨ãŒ', 'ã“ã¨ã§', 'ã“ã¨ã«', 'ã“ã¨ã‚’', 'ãŸã‚', 'ã‚ˆã†', 'ã‚ˆã†ã«',
            'ã¦ã„ã‚‹', 'ã¦ã„ã¾ã™', 'ã¦ãŠã‚Š', 'ã¦ã‚ã‚Š'
        ]
        words = [word for word in words if word not in stop_words and len(word) >= 2]
        
        # é »å‡ºå˜èªã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        word_freq = Counter(words)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        st.info(f"ğŸ” æŠ½å‡ºã—ãŸå…¨å˜èªæ•°: {len(words)}, ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°: {len(word_freq)}")
        
        if len(word_freq) == 0:
            st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            st.info("ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            # ãƒ‡ãƒãƒƒã‚°: å…ƒãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            with st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°: å…ƒãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«"):
                st.write(f"å…¨ãƒ†ã‚­ã‚¹ãƒˆã®æœ€åˆã®500æ–‡å­—:")
                st.text(all_text[:500])
            return
        
        # çµæœè¡¨ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ”¤ é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ Top 20")
            top_words = word_freq.most_common(20)
            
            if top_words:
                words_df = pd.DataFrame(top_words, columns=['å˜èª', 'å‡ºç¾å›æ•°'])
                st.dataframe(words_df, use_container_width=True)
            else:
                st.info("æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
        
        with col2:
            st.subheader("ğŸ“Š ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‡ºç¾é »åº¦")
            if top_words:
                words_df = pd.DataFrame(top_words[:10], columns=['å˜èª', 'å‡ºç¾å›æ•°'])
                
                fig = px.bar(
                    words_df, 
                    x='å‡ºç¾å›æ•°', 
                    y='å˜èª',
                    orientation='h',
                    title="Top 10 ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
                    color='å‡ºç¾å›æ•°',
                    color_continuous_scale='Blues'
                )
                
                fig.update_layout(
                    height=400,
                    template="plotly_white",
                    yaxis={'categoryorder': 'total ascending'}
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆ
        st.subheader("ğŸ“ˆ ãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆ")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°", len(text_data))
        
        with col2:
            avg_length = text_data.str.len().mean()
            st.metric("å¹³å‡æ–‡å­—æ•°", f"{avg_length:.1f}")
        
        with col3:
            st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°", len(word_freq))
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ
        with st.expander("ğŸ’¬ ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ"):
            sample_comments = text_data.sample(min(5, len(text_data)))
            for i, comment in enumerate(sample_comments, 1):
                st.write(f"**{i}.** {comment}")
                
    except Exception as e:
        st.error(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.info("ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    main()