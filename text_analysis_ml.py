#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹å¾“æ¥­å“¡æº€è¶³åº¦äºˆæ¸¬æ©Ÿèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªã®è‡ªç„¶è¨€èªå‡¦ç†ç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import janome
    from janome.tokenizer import Tokenizer
    TOKENIZER_TYPE = "janome"
    tokenizer = Tokenizer()
except ImportError:
    try:
        import MeCab
        TOKENIZER_TYPE = "mecab"
        mecab = MeCab.Tagger("-Owakati")
    except ImportError:
        TOKENIZER_TYPE = "simple"

def japanese_tokenizer(text):
    """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®å½¢æ…‹ç´ è§£æ"""
    if not text or pd.isna(text):
        return []
    
    text = str(text).strip()
    if not text:
        return []
    
    try:
        if TOKENIZER_TYPE == "janome":
            tokens = [token.surface for token in tokenizer.tokenize(text, wakati=True)]
        elif TOKENIZER_TYPE == "mecab":
            tokens = mecab.parse(text).strip().split()
        else:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªåˆ†å‰²ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            tokens = re.findall(r'\w+', text)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_tokens = []
        for token in tokens:
            if len(token) >= 2 and not token.isdigit():
                filtered_tokens.append(token)
        
        return filtered_tokens
    except Exception:
        return []

def create_sample_data_for_ml(n_samples=150):
    """æ©Ÿæ¢°å­¦ç¿’ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    np.random.seed(42)
    
    # ä¸»è¦KPIã®ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚³ã‚¢ç”Ÿæˆ
    data = []
    
    # ä½æº€è¶³åº¦ã‚°ãƒ«ãƒ¼ãƒ— (ä¸‹ä½20% - ãƒ©ãƒ™ãƒ«1)
    low_satisfaction_samples = int(n_samples * 0.2)
    for i in range(low_satisfaction_samples):
        recommend_score = np.random.choice([0, 1, 2, 3, 4, 5, 6], p=[0.1, 0.15, 0.2, 0.25, 0.15, 0.1, 0.05])
        overall_satisfaction = np.random.choice([1, 2, 3], p=[0.4, 0.4, 0.2])
        long_term_intention = np.random.choice([1, 2, 3], p=[0.5, 0.3, 0.2])
        sense_of_contribution = np.random.choice([1, 2, 3], p=[0.4, 0.4, 0.2])
        
        # ä½æº€è¶³åº¦ã«é–¢é€£ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        negative_words = [
            "ä¸æº€", "æ”¹å–„", "å•é¡Œ", "èª²é¡Œ", "å³ã—ã„", "å¤§å¤‰", "å›°é›£", "ã‚¹ãƒˆãƒ¬ã‚¹", "ç–²åŠ´", "è² æ‹…",
            "ä¸å®‰", "å¿ƒé…", "æœŸå¾…", "å¸Œæœ›", "è¦æœ›", "æ®‹æ¥­", "å¿™ã—ã„", "æ™‚é–“", "çµ¦ä¸", "è©•ä¾¡",
            "ä¸Šå¸", "åŒåƒš", "äººé–“é–¢ä¿‚", "ç’°å¢ƒ", "åˆ¶åº¦", "ã‚·ã‚¹ãƒ†ãƒ ", "æ¥­å‹™", "ä»•äº‹", "ä¼šç¤¾",
            "çµŒå–¶", "æˆ¦ç•¥", "æ–¹é‡", "å¤‰æ›´", "æ”¹é©", "å°†æ¥", "ã‚­ãƒ£ãƒªã‚¢", "æˆé•·", "æ©Ÿä¼š"
        ]
        
        comment_words = np.random.choice(negative_words, size=np.random.randint(8, 15), replace=True)
        comment = " ".join(comment_words) + "ã«ã¤ã„ã¦ä¸æº€ã‚’æ„Ÿã˜ã¦ã„ã¾ã™ã€‚æ”¹å–„ãŒå¿…è¦ã ã¨æ€ã„ã¾ã™ã€‚"
        
        data.append({
            'recommend_score': recommend_score,
            'overall_satisfaction': overall_satisfaction,
            'long_term_intention': long_term_intention,
            'sense_of_contribution': sense_of_contribution,
            'comment': comment,
            'is_low_satisfaction': 1  # ä¸‹ä½20%
        })
    
    # ä¸­ãƒ»é«˜æº€è¶³åº¦ã‚°ãƒ«ãƒ¼ãƒ— (ä¸Šä½80% - ãƒ©ãƒ™ãƒ«0)
    high_satisfaction_samples = n_samples - low_satisfaction_samples
    for i in range(high_satisfaction_samples):
        recommend_score = np.random.choice([6, 7, 8, 9, 10], p=[0.1, 0.2, 0.3, 0.25, 0.15])
        overall_satisfaction = np.random.choice([3, 4, 5], p=[0.3, 0.4, 0.3])
        long_term_intention = np.random.choice([3, 4, 5], p=[0.3, 0.4, 0.3])
        sense_of_contribution = np.random.choice([3, 4, 5], p=[0.3, 0.4, 0.3])
        
        # é«˜æº€è¶³åº¦ã«é–¢é€£ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        positive_words = [
            "æº€è¶³", "è‰¯ã„", "ç´ æ™´ã‚‰ã—ã„", "å„ªç§€", "å……å®Ÿ", "å®‰å¿ƒ", "å¿«é©", "åŠ¹ç‡", "æˆé•·", "å­¦ç¿’",
            "é”æˆ", "æˆåŠŸ", "è©•ä¾¡", "èªã‚ã‚‰ã‚Œã‚‹", "æ”¯æ´", "ã‚µãƒãƒ¼ãƒˆ", "å”åŠ›", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯", "ä¿¡é ¼", "å°Šé‡",
            "è‡ªç”±", "è£é‡", "è²¬ä»»", "æŒ‘æˆ¦", "æ©Ÿä¼š", "å¯èƒ½æ€§", "å°†æ¥", "ã‚­ãƒ£ãƒªã‚¢", "æ˜‡é€²", "æ˜‡æ ¼",
            "çµ¦ä¸", "å¾…é‡", "ç¦åˆ©åšç”Ÿ", "ä¼‘æš‡", "åƒãã‚„ã™ã„", "ç’°å¢ƒ", "åˆ¶åº¦", "ã‚·ã‚¹ãƒ†ãƒ ", "åŠ¹ç‡åŒ–"
        ]
        
        comment_words = np.random.choice(positive_words, size=np.random.randint(8, 15), replace=True)
        comment = " ".join(comment_words) + "ã«æº€è¶³ã—ã¦ãŠã‚Šã€ä»Šå¾Œã‚‚ç¶™ç¶šã—ã¦åƒããŸã„ã¨æ€ã„ã¾ã™ã€‚"
        
        data.append({
            'recommend_score': recommend_score,
            'overall_satisfaction': overall_satisfaction,
            'long_term_intention': long_term_intention,
            'sense_of_contribution': sense_of_contribution,
            'comment': comment,
            'is_low_satisfaction': 0  # ä¸Šä½80%
        })
    
    return pd.DataFrame(data)

def identify_low_performers(df, kpi_column, threshold_percentile=20):
    """ä¸»è¦KPIã®ä¸‹ä½20%ã‚’ç‰¹å®š"""
    if kpi_column not in df.columns:
        return pd.Series([0] * len(df))
    
    threshold = df[kpi_column].quantile(threshold_percentile / 100)
    return (df[kpi_column] <= threshold).astype(int)

def preprocess_text_features(comments):
    """ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã¨ç‰¹å¾´é‡æŠ½å‡º"""
    if len(comments) == 0:
        return pd.DataFrame()
    
    # ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    cleaned_comments = []
    for comment in comments:
        if pd.isna(comment):
            cleaned_comments.append("")
        else:
            # åŸºæœ¬çš„ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            text = str(comment).strip()
            text = re.sub(r'[^\w\s]', ' ', text)  # å¥èª­ç‚¹ã‚’é™¤å»
            text = re.sub(r'\s+', ' ', text)  # è¤‡æ•°ã‚¹ãƒšãƒ¼ã‚¹ã‚’å˜ä¸€ã‚¹ãƒšãƒ¼ã‚¹ã«
            cleaned_comments.append(text)
    
    # TF-IDFç‰¹å¾´é‡ã®ä½œæˆ
    try:
        # ã‚«ã‚¹ã‚¿ãƒ å½¢æ…‹ç´ è§£æå™¨ã‚’ä½¿ç”¨
        def custom_tokenizer(text):
            tokens = japanese_tokenizer(text)
            return tokens if tokens else ['']
        
        # TF-IDF Vectorizerï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        vectorizer = TfidfVectorizer(
            tokenizer=custom_tokenizer,
            max_features=100,  # ä¸Šä½100å€‹ã®ç‰¹å¾´é‡
            min_df=2,  # æœ€ä½2å›å‡ºç¾
            max_df=0.8,  # 80%ä»¥ä¸Šã®æ–‡æ›¸ã«å‡ºç¾ã™ã‚‹å˜èªã¯é™¤å¤–
            ngram_range=(1, 2)  # 1-gram ã¨ 2-gram
        )
        
        tfidf_matrix = vectorizer.fit_transform(cleaned_comments)
        feature_names = vectorizer.get_feature_names_out()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        tfidf_df = pd.DataFrame(
            tfidf_matrix.toarray(),
            columns=[f"word_{name}" for name in feature_names]
        )
        
        return tfidf_df, vectorizer
        
    except Exception as e:
        st.error(f"ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªå˜èªã‚«ã‚¦ãƒ³ãƒˆ
        word_counts = pd.DataFrame()
        return word_counts, None

def train_ensemble_models(X, y):
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
    models = {
        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=6)
    }
    
    trained_models = {}
    model_scores = {}
    
    for name, model in models.items():
        try:
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model.fit(X_train, y_train)
            
            # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')
            
            # ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢
            test_score = model.score(X_test, y_test)
            
            trained_models[name] = model
            model_scores[name] = {
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'test_score': test_score,
                'train_score': model.score(X_train, y_train)
            }
            
        except Exception as e:
            st.warning(f"{name}ã®è¨“ç·´ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    return trained_models, model_scores, X_test, y_test

def visualize_feature_importance(models, feature_names, top_n=20):
    """ç‰¹å¾´é‡é‡è¦æ€§ã®å¯è¦–åŒ–"""
    fig = make_subplots(
        rows=len(models), cols=1,
        subplot_titles=[f"{name} - ç‰¹å¾´é‡é‡è¦æ€§" for name in models.keys()],
        vertical_spacing=0.1
    )
    
    for i, (model_name, model) in enumerate(models.items(), 1):
        if hasattr(model, 'feature_importances_'):
            # ç‰¹å¾´é‡é‡è¦æ€§ã‚’å–å¾—
            importances = model.feature_importances_
            
            # é‡è¦æ€§ã§ã‚½ãƒ¼ãƒˆ
            indices = np.argsort(importances)[::-1][:top_n]
            top_features = [feature_names[idx] for idx in indices]
            top_importances = importances[indices]
            
            # ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆè¿½åŠ 
            fig.add_trace(
                go.Bar(
                    y=top_features[::-1],  # é‡è¦åº¦é †ã«è¡¨ç¤º
                    x=top_importances[::-1],
                    orientation='h',
                    name=model_name,
                    showlegend=False
                ),
                row=i, col=1
            )
    
    fig.update_layout(
        height=300 * len(models),
        title="ç‰¹å¾´é‡é‡è¦æ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼‰",
        title_font_size=16
    )
    
    fig.update_xaxes(title_text="é‡è¦æ€§ã‚¹ã‚³ã‚¢")
    
    return fig

def create_prediction_summary(models, model_scores):
    """äºˆæ¸¬çµæœã‚µãƒãƒªãƒ¼ã®ä½œæˆ"""
    summary_data = []
    
    for model_name, scores in model_scores.items():
        summary_data.append({
            'ãƒ¢ãƒ‡ãƒ«': model_name,
            'è¨“ç·´ç²¾åº¦': f"{scores['train_score']:.3f}",
            'ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦': f"{scores['cv_mean']:.3f} (Â±{scores['cv_std']:.3f})",
            'ãƒ†ã‚¹ãƒˆç²¾åº¦': f"{scores['test_score']:.3f}"
        })
    
    return pd.DataFrame(summary_data)

def show_text_analysis_ml_page():
    """ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨æ©Ÿæ¢°å­¦ç¿’ãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                color: white; padding: 2rem; border-radius: 12px; margin-bottom: 2rem; text-align: center;">
        <h2 style="margin: 0; color: white;">ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ Ã— æ©Ÿæ¢°å­¦ç¿’</h2>
        <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æã«ã‚ˆã‚‹æº€è¶³åº¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­..."):
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
        df = create_sample_data_for_ml(200)
        st.success(f"åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã—ãŸ: {len(df)}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«")
    
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        low_satisfaction_count = df['is_low_satisfaction'].sum()
        st.metric("ä¸‹ä½20%ï¼ˆæ”¹å–„å¯¾è±¡ï¼‰", f"{low_satisfaction_count}äºº", 
                 f"{low_satisfaction_count/len(df)*100:.1f}%")
    
    with col2:
        avg_recommend = df['recommend_score'].mean()
        st.metric("å¹³å‡æ¨å¥¨ã‚¹ã‚³ã‚¢", f"{avg_recommend:.1f}")
    
    with col3:
        avg_satisfaction = df['overall_satisfaction'].mean()
        st.metric("å¹³å‡ç·åˆæº€è¶³åº¦", f"{avg_satisfaction:.1f}")
    
    with col4:
        unique_words = len(set(' '.join(df['comment']).split()))
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°", f"{unique_words:,}")
    
    # ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†å‰²
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«", "ğŸ“ˆ ç‰¹å¾´é‡é‡è¦æ€§", "ğŸ¯ äºˆæ¸¬çµæœ"])
    
    with tab1:
        st.subheader("ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒåˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # KPIåˆ†å¸ƒ
            fig_kpi = px.histogram(
                df, x='overall_satisfaction', color='is_low_satisfaction',
                title="ç·åˆæº€è¶³åº¦ã®åˆ†å¸ƒ", 
                labels={'is_low_satisfaction': 'ä¸‹ä½20%ãƒ•ãƒ©ã‚°'},
                color_discrete_map={0: '#2E86AB', 1: '#F24236'}
            )
            st.plotly_chart(fig_kpi, use_container_width=True)
        
        with col2:
            # æ¨å¥¨ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
            fig_nps = px.histogram(
                df, x='recommend_score', color='is_low_satisfaction',
                title="æ¨å¥¨ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ",
                labels={'is_low_satisfaction': 'ä¸‹ä½20%ãƒ•ãƒ©ã‚°'},
                color_discrete_map={0: '#2E86AB', 1: '#F24236'}
            )
            st.plotly_chart(fig_nps, use_container_width=True)
        
        # ã‚³ãƒ¡ãƒ³ãƒˆã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        st.subheader("ã‚³ãƒ¡ãƒ³ãƒˆã‚µãƒ³ãƒ—ãƒ«")
        sample_comments = df.sample(5)[['overall_satisfaction', 'recommend_score', 'is_low_satisfaction', 'comment']]
        st.dataframe(sample_comments, use_container_width=True)
    
    with tab2:
        st.subheader("æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´")
        
        if st.button("ğŸš€ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ", type="primary"):
            with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡æŠ½å‡ºä¸­..."):
                # ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡æŠ½å‡º
                text_features, vectorizer = preprocess_text_features(df['comment'])
                
                if len(text_features.columns) > 0:
                    # æ•°å€¤ç‰¹å¾´é‡ã¨çµåˆ
                    numeric_features = df[['recommend_score', 'overall_satisfaction', 'long_term_intention', 'sense_of_contribution']]
                    X = pd.concat([numeric_features, text_features], axis=1)
                    y = df['is_low_satisfaction']
                    
                    st.success(f"ç‰¹å¾´é‡æº–å‚™å®Œäº†: {X.shape[1]}å€‹ã®ç‰¹å¾´é‡")
                    
                    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
                    with st.spinner("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­..."):
                        models, scores, X_test, y_test = train_ensemble_models(X, y)
                        
                        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                        st.session_state['ml_models'] = models
                        st.session_state['ml_scores'] = scores
                        st.session_state['ml_feature_names'] = X.columns.tolist()
                        st.session_state['ml_vectorizer'] = vectorizer
                        
                        st.success("âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†ï¼")
                        
                        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚µãƒãƒªãƒ¼
                        summary_df = create_prediction_summary(models, scores)
                        st.subheader("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ")
                        st.dataframe(summary_df, use_container_width=True)
                        
                else:
                    st.error("ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    with tab3:
        st.subheader("ç‰¹å¾´é‡é‡è¦æ€§åˆ†æ")
        
        if 'ml_models' in st.session_state:
            models = st.session_state['ml_models']
            feature_names = st.session_state['ml_feature_names']
            
            # ç‰¹å¾´é‡é‡è¦æ€§ã‚’å¯è¦–åŒ–
            fig_importance = visualize_feature_importance(models, feature_names, top_n=15)
            st.plotly_chart(fig_importance, use_container_width=True)
            
            # ãƒˆãƒƒãƒ—ç‰¹å¾´é‡ã®è©³ç´°
            st.subheader("é‡è¦ãªç‰¹å¾´é‡ã®è©³ç´°")
            
            for model_name, model in models.items():
                if hasattr(model, 'feature_importances_'):
                    st.write(f"**{model_name}**")
                    
                    importances = model.feature_importances_
                    indices = np.argsort(importances)[::-1][:10]
                    
                    top_features_data = []
                    for i, idx in enumerate(indices):
                        feature_name = feature_names[idx]
                        importance = importances[idx]
                        
                        # ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã®å ´åˆã¯å˜èªã‚’æŠ½å‡º
                        if feature_name.startswith('word_'):
                            word = feature_name.replace('word_', '')
                            feature_type = "ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡"
                        else:
                            word = feature_name
                            feature_type = "æ•°å€¤ç‰¹å¾´é‡"
                        
                        top_features_data.append({
                            'ãƒ©ãƒ³ã‚¯': i + 1,
                            'ç‰¹å¾´é‡': word,
                            'ã‚¿ã‚¤ãƒ—': feature_type,
                            'é‡è¦æ€§': f"{importance:.4f}"
                        })
                    
                    st.dataframe(pd.DataFrame(top_features_data), use_container_width=True)
                    st.write("---")
        else:
            st.info("ã¾ãšã€Œæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ã‚¿ãƒ–ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ãã ã•ã„ã€‚")
    
    with tab4:
        st.subheader("äºˆæ¸¬ã¨è§£é‡ˆ")
        
        if 'ml_models' in st.session_state:
            models = st.session_state['ml_models']
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆå¤šæ•°æ±ºï¼‰
            st.write("### ğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®ä»•çµ„ã¿")
            st.info("""
            **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã®åˆ©ç‚¹:**
            - è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§äºˆæ¸¬ç²¾åº¦ãŒå‘ä¸Š
            - å€‹ã€…ã®ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’è£œå®Œ
            - ã‚ˆã‚Šå …ç‰¢ã§ä¿¡é ¼æ€§ã®é«˜ã„äºˆæ¸¬ãŒå¯èƒ½
            
            **ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«:**
            - Decision Tree: è§£é‡ˆã—ã‚„ã™ã„ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
            - Random Forest: è¤‡æ•°ã®æ±ºå®šæœ¨ã«ã‚ˆã‚‹äºˆæ¸¬ã®å¹³å‡åŒ–
            - Gradient Boosting: æ®µéšçš„ã«äºˆæ¸¬ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•
            """)
            
            # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬
            sample_idx = st.slider("äºˆæ¸¬å¯¾è±¡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ", 0, len(df)-1, 0)
            sample_data = df.iloc[sample_idx]
            
            st.write(f"**é¸æŠã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ« #{sample_idx}**")
            st.write(f"- æ¨å¥¨ã‚¹ã‚³ã‚¢: {sample_data['recommend_score']}")
            st.write(f"- ç·åˆæº€è¶³åº¦: {sample_data['overall_satisfaction']}")
            st.write(f"- å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«: {'ä¸‹ä½20%' if sample_data['is_low_satisfaction'] else 'ä¸Šä½80%'}")
            st.write(f"- ã‚³ãƒ¡ãƒ³ãƒˆ: {sample_data['comment'][:100]}...")
            
            # å®Ÿè£…ã®è©³ç´°ï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯äºˆæ¸¬æ©Ÿèƒ½ã‚’å®Ÿè£…ï¼‰
            st.write("### ğŸ“Š äºˆæ¸¬çµæœ")
            st.info("äºˆæ¸¬æ©Ÿèƒ½ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿè£…æ™‚ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
            
        else:
            st.info("ã¾ãšã€Œæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ã‚¿ãƒ–ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    show_text_analysis_ml_page()